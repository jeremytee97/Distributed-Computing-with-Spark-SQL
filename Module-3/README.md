# Module 3 - Engineering Data Pipelines

In this module, I was able to identify and discuss the general demands of data applications. I was also able to access data in a variety of formats and compare and contrast the tradeoffs between these formats.

Next, I explored and examined semi-structured JSON data, which is common in big data environments, schemas, and parallel data writes. Finally, I was able to create an end-to-end pipeline that reads data, transforms it, and saves the result.

Useful readings:
1. [Why You Should Care about Data Layout in the Filesystem](https://databricks.com/session/why-you-should-care-about-data-layout-in-the-filesystem)
2. [Lessons From the Field: Applying Best Practices to Your Apache Spark Applications](https://www.youtube.com/watch?v=iwQel6JHMpA)
3. [Wâ€‹orking with Complex Data Formats with Structured Streaming in Apache Spark 2.1: Part 2 of Scalable Data at Databricks](https://databricks.com/blog/2017/02/23/working-complex-data-formats-structured-streaming-apache-spark-2-1.html)